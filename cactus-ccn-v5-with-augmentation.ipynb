{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<font size=\"5\">**Cactus Image Classification using Convolutional Neural Networks**</font>\n",
    "\n",
    "This is notebook is a submission file for a Kaggle competition: Aerial Cactus Identification\n",
    "(link: https://www.kaggle.com/c/aerial-cactus-identification/overview)\n",
    "\n",
    "The submission achieved **99.8% accuracy** on the held out test set. \n",
    "\n",
    "A convolutional neural network (**CNN**) is used, which was created using **tensorflow**.\\\n",
    "**Data augmentation** was employed: 45 angle rotations and horizontal flips were used as these transformation would create images that would resemble the original images. (Vertical flips would result in upside down cacti which would not be a realistic image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test', 'train', 'train.csv', 'sample_submission.csv']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np  # linear algebra\n",
    "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import tensorflow as tf  # the deep learning library and all its components\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,ReduceLROnPlateau, LambdaCallback, CSVLogger, TensorBoard\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "import skimage\n",
    "\n",
    "import cv2  # computer vision library\n",
    "\n",
    "from sklearn.model_selection import train_test_split  # function used for data splitting \n",
    "import matplotlib.pyplot as plt  # library used for training curve plotting\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>has_cactus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0004be2cfeaba1c0361d39e2b000257b.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000c8a36845c0208e833c79c1bffedd1.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000d1e9a533f62e55c289303b072733d.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0011485b40695e9138e92d0b3fb55128.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0014d7a11e90b62848904c1418fc8cf2.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id  has_cactus\n",
       "0  0004be2cfeaba1c0361d39e2b000257b.jpg           1\n",
       "1  000c8a36845c0208e833c79c1bffedd1.jpg           1\n",
       "2  000d1e9a533f62e55c289303b072733d.jpg           1\n",
       "3  0011485b40695e9138e92d0b3fb55128.jpg           1\n",
       "4  0014d7a11e90b62848904c1418fc8cf2.jpg           1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"../input/train.csv\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "b811722518b633f2a0e03d681170b6d32baf83db"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0004be2cfeaba1c0361d39e2b000257b.jpg',\n",
       " '000c8a36845c0208e833c79c1bffedd1.jpg',\n",
       " '000d1e9a533f62e55c289303b072733d.jpg',\n",
       " '0011485b40695e9138e92d0b3fb55128.jpg',\n",
       " '0014d7a11e90b62848904c1418fc8cf2.jpg']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#defining basic variables (data directories, image shape) and reading in some data\n",
    "\n",
    "Train_Dir = \"../input/train/train/\"\n",
    "train_labels = \"../input/train.csv\"\n",
    "Test_Dir = \"../input/test/test/\"\n",
    "\n",
    "img_shape = (32,32,3)\n",
    "\n",
    "label_list = list(train_df['has_cactus'])\n",
    "img_id_list = list(train_df['id'])\n",
    "img_id_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "3908e04f70cc165abfd5afb8745b10ce24950b8f"
   },
   "outputs": [],
   "source": [
    "# functions for reading an image given path\n",
    "def read_img(image, Dir):\n",
    "    img = cv2.imread(Dir + image)\n",
    "    return img\n",
    "\n",
    "# function for reading and normalizing image given path\n",
    "def read_standard_img(image, Dir):\n",
    "    img = read_img(image, Dir)\n",
    "    img = img/255  # divide by 255 so all pixels are between 0 and 1\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "f545b16c12bec34294fd4ed9e0b9a8d0833702cd"
   },
   "outputs": [],
   "source": [
    "# here we randomly split the data into training and validation sets with a 85%-15% split \n",
    "# two lists of images are created: a training and a validation list\n",
    "\n",
    "split_ratio = 0.15\n",
    "\n",
    "train_img_id, val_img_id, train_label_list, val_label_list = train_test_split\\\n",
    "                    (img_id_list,label_list, test_size = split_ratio, random_state = 21)\n",
    "train_img_list = []\n",
    "for img in train_img_id:\n",
    "    train_img_list.append(read_standard_img(img, Train_Dir))\n",
    "    \n",
    "val_img_list = []\n",
    "for img in val_img_id:\n",
    "    val_img_list.append(read_standard_img(img,Train_Dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[0.25490196, 0.31764706, 0.40784314],\n",
       "         [0.2745098 , 0.3372549 , 0.42745098],\n",
       "         [0.29019608, 0.35686275, 0.43921569],\n",
       "         ...,\n",
       "         [0.30588235, 0.34509804, 0.4627451 ],\n",
       "         [0.40392157, 0.44313725, 0.56078431],\n",
       "         [0.2627451 , 0.30196078, 0.41960784]],\n",
       " \n",
       "        [[0.25098039, 0.31372549, 0.40392157],\n",
       "         [0.27058824, 0.33333333, 0.42352941],\n",
       "         [0.30588235, 0.37254902, 0.45490196],\n",
       "         ...,\n",
       "         [0.30588235, 0.34509804, 0.4627451 ],\n",
       "         [0.35686275, 0.39607843, 0.51372549],\n",
       "         [0.29019608, 0.32941176, 0.44705882]],\n",
       " \n",
       "        [[0.16862745, 0.23529412, 0.31764706],\n",
       "         [0.16470588, 0.23137255, 0.31372549],\n",
       "         [0.15686275, 0.22352941, 0.30588235],\n",
       "         ...,\n",
       "         [0.40784314, 0.44705882, 0.56470588],\n",
       "         [0.37647059, 0.41568627, 0.53333333],\n",
       "         [0.20392157, 0.24313725, 0.36078431]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.38823529, 0.44313725, 0.53333333],\n",
       "         [0.41176471, 0.46666667, 0.55686275],\n",
       "         [0.41568627, 0.47058824, 0.56078431],\n",
       "         ...,\n",
       "         [0.29803922, 0.34509804, 0.43921569],\n",
       "         [0.45098039, 0.49803922, 0.59215686],\n",
       "         [0.51764706, 0.56470588, 0.65882353]],\n",
       " \n",
       "        [[0.35294118, 0.40784314, 0.49803922],\n",
       "         [0.36470588, 0.41960784, 0.50980392],\n",
       "         [0.28627451, 0.34117647, 0.43137255],\n",
       "         ...,\n",
       "         [0.25098039, 0.29803922, 0.39215686],\n",
       "         [0.29019608, 0.3372549 , 0.43137255],\n",
       "         [0.33333333, 0.38039216, 0.4745098 ]],\n",
       " \n",
       "        [[0.2627451 , 0.31764706, 0.40784314],\n",
       "         [0.2745098 , 0.32941176, 0.41960784],\n",
       "         [0.28627451, 0.34117647, 0.43137255],\n",
       "         ...,\n",
       "         [0.29411765, 0.34117647, 0.43529412],\n",
       "         [0.28627451, 0.33333333, 0.42745098],\n",
       "         [0.3372549 , 0.38431373, 0.47843137]]]),\n",
       " array([[[0.38431373, 0.48235294, 0.49019608],\n",
       "         [0.39215686, 0.49019608, 0.49803922],\n",
       "         [0.3372549 , 0.42745098, 0.43529412],\n",
       "         ...,\n",
       "         [0.27843137, 0.30588235, 0.38431373],\n",
       "         [0.24705882, 0.26666667, 0.34901961],\n",
       "         [0.29019608, 0.30980392, 0.39215686]],\n",
       " \n",
       "        [[0.32156863, 0.41960784, 0.42745098],\n",
       "         [0.3254902 , 0.42352941, 0.43137255],\n",
       "         [0.29019608, 0.38039216, 0.38823529],\n",
       "         ...,\n",
       "         [0.16078431, 0.18823529, 0.26666667],\n",
       "         [0.18039216, 0.2       , 0.28235294],\n",
       "         [0.31372549, 0.33333333, 0.41568627]],\n",
       " \n",
       "        [[0.3254902 , 0.42352941, 0.43137255],\n",
       "         [0.31764706, 0.41568627, 0.42352941],\n",
       "         [0.29019608, 0.38039216, 0.38823529],\n",
       "         ...,\n",
       "         [0.11372549, 0.14117647, 0.21960784],\n",
       "         [0.15294118, 0.17254902, 0.25490196],\n",
       "         [0.33333333, 0.35294118, 0.43529412]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.36078431, 0.41176471, 0.4745098 ],\n",
       "         [0.36078431, 0.41176471, 0.4745098 ],\n",
       "         [0.35686275, 0.40784314, 0.47058824],\n",
       "         ...,\n",
       "         [0.50980392, 0.54117647, 0.59215686],\n",
       "         [0.51764706, 0.54117647, 0.58431373],\n",
       "         [0.51372549, 0.5372549 , 0.58039216]],\n",
       " \n",
       "        [[0.35686275, 0.40784314, 0.47058824],\n",
       "         [0.35294118, 0.40392157, 0.46666667],\n",
       "         [0.34901961, 0.4       , 0.4627451 ],\n",
       "         ...,\n",
       "         [0.51764706, 0.55294118, 0.59215686],\n",
       "         [0.5254902 , 0.54901961, 0.59215686],\n",
       "         [0.52156863, 0.54509804, 0.58823529]],\n",
       " \n",
       "        [[0.34117647, 0.39215686, 0.45490196],\n",
       "         [0.33333333, 0.38431373, 0.44705882],\n",
       "         [0.34117647, 0.39215686, 0.45490196],\n",
       "         ...,\n",
       "         [0.52941176, 0.56470588, 0.60392157],\n",
       "         [0.5372549 , 0.56078431, 0.60392157],\n",
       "         [0.5372549 , 0.56078431, 0.60392157]]]),\n",
       " array([[[0.41176471, 0.37647059, 0.45490196],\n",
       "         [0.41568627, 0.38039216, 0.45882353],\n",
       "         [0.41176471, 0.37647059, 0.45490196],\n",
       "         ...,\n",
       "         [0.36078431, 0.35294118, 0.35294118],\n",
       "         [0.36862745, 0.36862745, 0.36862745],\n",
       "         [0.35294118, 0.35294118, 0.35294118]],\n",
       " \n",
       "        [[0.41960784, 0.38431373, 0.4627451 ],\n",
       "         [0.41568627, 0.38039216, 0.45882353],\n",
       "         [0.39215686, 0.35686275, 0.43529412],\n",
       "         ...,\n",
       "         [0.38431373, 0.37647059, 0.37647059],\n",
       "         [0.34509804, 0.34509804, 0.34509804],\n",
       "         [0.28235294, 0.28235294, 0.28235294]],\n",
       " \n",
       "        [[0.41568627, 0.39215686, 0.45882353],\n",
       "         [0.42352941, 0.4       , 0.46666667],\n",
       "         [0.37647059, 0.35294118, 0.41960784],\n",
       "         ...,\n",
       "         [0.22745098, 0.21960784, 0.21960784],\n",
       "         [0.25490196, 0.25490196, 0.25490196],\n",
       "         [0.14509804, 0.14509804, 0.14509804]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.43529412, 0.36078431, 0.45882353],\n",
       "         [0.44705882, 0.37254902, 0.47058824],\n",
       "         [0.35686275, 0.29411765, 0.38823529],\n",
       "         ...,\n",
       "         [0.30980392, 0.29019608, 0.3254902 ],\n",
       "         [0.25490196, 0.24313725, 0.27843137],\n",
       "         [0.21960784, 0.20784314, 0.24313725]],\n",
       " \n",
       "        [[0.37647059, 0.30196078, 0.4       ],\n",
       "         [0.42352941, 0.34901961, 0.44705882],\n",
       "         [0.37254902, 0.30980392, 0.40392157],\n",
       "         ...,\n",
       "         [0.23137255, 0.21960784, 0.25490196],\n",
       "         [0.25098039, 0.23921569, 0.2745098 ],\n",
       "         [0.22352941, 0.21568627, 0.23921569]],\n",
       " \n",
       "        [[0.44313725, 0.36862745, 0.46666667],\n",
       "         [0.43137255, 0.35686275, 0.45490196],\n",
       "         [0.39215686, 0.32941176, 0.42352941],\n",
       "         ...,\n",
       "         [0.23529412, 0.22352941, 0.25882353],\n",
       "         [0.23137255, 0.22352941, 0.24705882],\n",
       "         [0.23529412, 0.22745098, 0.25098039]]]),\n",
       " array([[[0.27843137, 0.3372549 , 0.34901961],\n",
       "         [0.27843137, 0.3372549 , 0.34901961],\n",
       "         [0.32156863, 0.36862745, 0.38431373],\n",
       "         ...,\n",
       "         [0.51372549, 0.54117647, 0.55294118],\n",
       "         [0.24705882, 0.2745098 , 0.28627451],\n",
       "         [0.3254902 , 0.35294118, 0.36470588]],\n",
       " \n",
       "        [[0.3254902 , 0.38431373, 0.39607843],\n",
       "         [0.2745098 , 0.33333333, 0.34509804],\n",
       "         [0.34117647, 0.38823529, 0.40392157],\n",
       "         ...,\n",
       "         [0.46666667, 0.49411765, 0.50588235],\n",
       "         [0.14117647, 0.16862745, 0.18039216],\n",
       "         [0.21568627, 0.24313725, 0.25490196]],\n",
       " \n",
       "        [[0.35686275, 0.41568627, 0.42745098],\n",
       "         [0.41568627, 0.4745098 , 0.48627451],\n",
       "         [0.43137255, 0.47843137, 0.49411765],\n",
       "         ...,\n",
       "         [0.22352941, 0.25098039, 0.2627451 ],\n",
       "         [0.49019608, 0.51764706, 0.52941176],\n",
       "         [0.48235294, 0.50980392, 0.52156863]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.27843137, 0.22745098, 0.29019608],\n",
       "         [0.30980392, 0.25882353, 0.32156863],\n",
       "         [0.3254902 , 0.2745098 , 0.3372549 ],\n",
       "         ...,\n",
       "         [0.30980392, 0.25882353, 0.32156863],\n",
       "         [0.30588235, 0.25490196, 0.31764706],\n",
       "         [0.30588235, 0.25490196, 0.31764706]],\n",
       " \n",
       "        [[0.29411765, 0.24313725, 0.30588235],\n",
       "         [0.32941176, 0.27843137, 0.34117647],\n",
       "         [0.37647059, 0.3254902 , 0.38823529],\n",
       "         ...,\n",
       "         [0.38431373, 0.33333333, 0.39607843],\n",
       "         [0.4       , 0.3372549 , 0.40392157],\n",
       "         [0.40392157, 0.34117647, 0.40784314]],\n",
       " \n",
       "        [[0.2627451 , 0.21176471, 0.2745098 ],\n",
       "         [0.27843137, 0.22745098, 0.29019608],\n",
       "         [0.34117647, 0.29019608, 0.35294118],\n",
       "         ...,\n",
       "         [0.4       , 0.34901961, 0.41176471],\n",
       "         [0.4       , 0.3372549 , 0.40392157],\n",
       "         [0.40784314, 0.34509804, 0.41176471]]]),\n",
       " array([[[0.49019608, 0.49803922, 0.63137255],\n",
       "         [0.45098039, 0.45882353, 0.59215686],\n",
       "         [0.4745098 , 0.49411765, 0.62352941],\n",
       "         ...,\n",
       "         [0.44313725, 0.48627451, 0.59607843],\n",
       "         [0.54117647, 0.57254902, 0.68627451],\n",
       "         [0.50588235, 0.5372549 , 0.65098039]],\n",
       " \n",
       "        [[0.45098039, 0.45882353, 0.59215686],\n",
       "         [0.45882353, 0.46666667, 0.6       ],\n",
       "         [0.4       , 0.41960784, 0.54901961],\n",
       "         ...,\n",
       "         [0.57254902, 0.61568627, 0.7254902 ],\n",
       "         [0.63137255, 0.6627451 , 0.77647059],\n",
       "         [0.53333333, 0.56470588, 0.67843137]],\n",
       " \n",
       "        [[0.36862745, 0.38039216, 0.50196078],\n",
       "         [0.45098039, 0.4627451 , 0.58431373],\n",
       "         [0.43137255, 0.45098039, 0.57254902],\n",
       "         ...,\n",
       "         [0.58823529, 0.61960784, 0.7372549 ],\n",
       "         [0.45490196, 0.48627451, 0.60392157],\n",
       "         [0.34509804, 0.37647059, 0.49411765]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.34117647, 0.34901961, 0.41960784],\n",
       "         [0.39215686, 0.4       , 0.47058824],\n",
       "         [0.38823529, 0.40392157, 0.4745098 ],\n",
       "         ...,\n",
       "         [0.45098039, 0.49411765, 0.64313725],\n",
       "         [0.46666667, 0.50588235, 0.6627451 ],\n",
       "         [0.49411765, 0.53333333, 0.69019608]],\n",
       " \n",
       "        [[0.27843137, 0.28627451, 0.35686275],\n",
       "         [0.30588235, 0.31372549, 0.38431373],\n",
       "         [0.33333333, 0.34901961, 0.41960784],\n",
       "         ...,\n",
       "         [0.49803922, 0.53333333, 0.68235294],\n",
       "         [0.49803922, 0.53333333, 0.68235294],\n",
       "         [0.51372549, 0.54901961, 0.69803922]],\n",
       " \n",
       "        [[0.32156863, 0.32941176, 0.4       ],\n",
       "         [0.31372549, 0.32156863, 0.39215686],\n",
       "         [0.31764706, 0.33333333, 0.40392157],\n",
       "         ...,\n",
       "         [0.43137255, 0.46666667, 0.61568627],\n",
       "         [0.47843137, 0.51372549, 0.6627451 ],\n",
       "         [0.49411765, 0.52941176, 0.67843137]]])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create list of test images from test directory \n",
    "\n",
    "test_img_id = os.listdir(Test_Dir)\n",
    "test_img_list = []\n",
    "for img in test_img_id:\n",
    "    test_img_list.append(read_standard_img(img, Test_Dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "flip_1=[]\n",
    "flip_1_labels=[]\n",
    "\n",
    "rot=[]\n",
    "rot_labels=[]\n",
    "\n",
    "counter=0\n",
    "\n",
    "for img in train_img_list:\n",
    "    flip_1.append(np.fliplr(img))\n",
    "    rot.append(skimage.transform.rotate(img, angle=45, mode='reflect'))\n",
    "    \n",
    "    if (train_label_list[counter] == 1):\n",
    "        flip_1_labels.append(1)\n",
    "        rot_labels.append(1)\n",
    "    else:\n",
    "        flip_1_labels.append(0)\n",
    "        rot_labels.append(0)\n",
    "        \n",
    "    counter=counter+1\n",
    "#     scale_out.append(skimage.transform.rescale(img, scale=2.0, mode='constant'))\n",
    "#     scale_in.append(skimage.transform.rescale(img, scale=0.5, mode='constant'))\n",
    "    \n",
    "#We need to augment the label list as well \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44625"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Augmenting the image set\n",
    "train_img_list = train_img_list + flip_1 + rot\n",
    "len(train_img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44625"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Augmenting the image labels\n",
    "train_label_list = train_label_list + flip_1_labels + rot_labels\n",
    "len(train_label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "7a092a38b70820ef94723976a35beb5a6b660978"
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    #tf.keras.backend.clear_session()\n",
    "    #optimizer = Adam(lr=0.001)\n",
    "    inputs = tf.keras.Input(shape=img_shape, name='input_branch')\n",
    "    x = Conv2D(32, (5,5), activation='relu', input_shape = img_shape)(inputs)\n",
    "    x = BatchNormalization(axis=3)(x)\n",
    "    x = MaxPool2D((2,2))(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Conv2D(64, (3,3), activation='relu')(x)\n",
    "    x = BatchNormalization(axis=3)(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Conv2D(64, (3,3), activation='relu')(x)\n",
    "    x = BatchNormalization(axis=3)(x)\n",
    "    x = MaxPool2D((2,2))(x)\n",
    "    x = Conv2D(64, (3,3), activation='relu')(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = BatchNormalization(axis=3)(x)\n",
    "    x = MaxPool2D((2,2))(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    \n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs,outputs = output, name='CNNmodel')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "d109919195a350111c5b83bffb2a5964f61e8ce2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_branch (InputLayer)    (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 28, 28, 32)        2432      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 12, 12, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 12, 12, 64)        256       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 10, 10, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_2 (Ba (None, 10, 10, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_3 (Ba (None, 3, 3, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 104,129\n",
      "Trainable params: 103,681\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Compiling the model that was designed in build_model()\n",
    "# Adam is used as the optimization function and binary crossentropy is used as the loss function\n",
    "\n",
    "model = build_model()\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "2c29fce53d741d1669299b520f672ce7e1a74f7d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 44625 samples, validate on 2625 samples\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/40\n",
      "44544/44625 [============================>.] - ETA: 0s - loss: 0.1413 - acc: 0.9428\n",
      "Epoch 00001: val_loss improved from inf to 1.77926, saving model to cactusCNN.h5\n",
      "44625/44625 [==============================] - 6s 133us/sample - loss: 0.1412 - acc: 0.9428 - val_loss: 1.7793 - val_acc: 0.2491\n",
      "Epoch 2/40\n",
      "43520/44625 [============================>.] - ETA: 0s - loss: 0.0731 - acc: 0.9718\n",
      "Epoch 00002: val_loss did not improve from 1.77926\n",
      "44625/44625 [==============================] - 2s 44us/sample - loss: 0.0725 - acc: 0.9722 - val_loss: 3.1682 - val_acc: 0.2491\n",
      "Epoch 3/40\n",
      "43520/44625 [============================>.] - ETA: 0s - loss: 0.0569 - acc: 0.9786\n",
      "Epoch 00003: val_loss improved from 1.77926 to 1.48182, saving model to cactusCNN.h5\n",
      "44625/44625 [==============================] - 2s 45us/sample - loss: 0.0566 - acc: 0.9787 - val_loss: 1.4818 - val_acc: 0.2773\n",
      "Epoch 4/40\n",
      "43520/44625 [============================>.] - ETA: 0s - loss: 0.0435 - acc: 0.9836\n",
      "Epoch 00004: val_loss improved from 1.48182 to 1.01709, saving model to cactusCNN.h5\n",
      "44625/44625 [==============================] - 2s 46us/sample - loss: 0.0433 - acc: 0.9837 - val_loss: 1.0171 - val_acc: 0.5878\n",
      "Epoch 5/40\n",
      "43520/44625 [============================>.] - ETA: 0s - loss: 0.0361 - acc: 0.9869\n",
      "Epoch 00005: val_loss did not improve from 1.01709\n",
      "44625/44625 [==============================] - 2s 44us/sample - loss: 0.0359 - acc: 0.9869 - val_loss: 1.1089 - val_acc: 0.6217\n",
      "Epoch 6/40\n",
      "43520/44625 [============================>.] - ETA: 0s - loss: 0.0337 - acc: 0.9877\n",
      "Epoch 00006: val_loss did not improve from 1.01709\n",
      "44625/44625 [==============================] - 2s 44us/sample - loss: 0.0339 - acc: 0.9876 - val_loss: 1.0258 - val_acc: 0.6903\n",
      "Epoch 7/40\n",
      "43520/44625 [============================>.] - ETA: 0s - loss: 0.0304 - acc: 0.9891\n",
      "Epoch 00007: val_loss improved from 1.01709 to 0.29468, saving model to cactusCNN.h5\n",
      "44625/44625 [==============================] - 2s 46us/sample - loss: 0.0305 - acc: 0.9890 - val_loss: 0.2947 - val_acc: 0.8724\n",
      "Epoch 8/40\n",
      "43520/44625 [============================>.] - ETA: 0s - loss: 0.0310 - acc: 0.9888\n",
      "Epoch 00008: val_loss improved from 0.29468 to 0.12196, saving model to cactusCNN.h5\n",
      "44625/44625 [==============================] - 2s 46us/sample - loss: 0.0308 - acc: 0.9889 - val_loss: 0.1220 - val_acc: 0.9554\n",
      "Epoch 9/40\n",
      "43520/44625 [============================>.] - ETA: 0s - loss: 0.0238 - acc: 0.9915\n",
      "Epoch 00009: val_loss improved from 0.12196 to 0.02593, saving model to cactusCNN.h5\n",
      "44625/44625 [==============================] - 2s 46us/sample - loss: 0.0236 - acc: 0.9916 - val_loss: 0.0259 - val_acc: 0.9912\n",
      "Epoch 10/40\n",
      "43520/44625 [============================>.] - ETA: 0s - loss: 0.0211 - acc: 0.9923\n",
      "Epoch 00010: val_loss did not improve from 0.02593\n",
      "44625/44625 [==============================] - 2s 45us/sample - loss: 0.0211 - acc: 0.9923 - val_loss: 0.5216 - val_acc: 0.8187\n",
      "Epoch 11/40\n",
      "44544/44625 [============================>.] - ETA: 0s - loss: 0.0211 - acc: 0.9924\n",
      "Epoch 00011: val_loss did not improve from 0.02593\n",
      "44625/44625 [==============================] - 2s 45us/sample - loss: 0.0211 - acc: 0.9924 - val_loss: 0.0809 - val_acc: 0.9726\n",
      "Epoch 12/40\n",
      "44544/44625 [============================>.] - ETA: 0s - loss: 0.0195 - acc: 0.9928\n",
      "Epoch 00012: val_loss did not improve from 0.02593\n",
      "44625/44625 [==============================] - 2s 45us/sample - loss: 0.0195 - acc: 0.9928 - val_loss: 0.1135 - val_acc: 0.9562\n",
      "Epoch 13/40\n",
      "43520/44625 [============================>.] - ETA: 0s - loss: 0.0165 - acc: 0.9941\n",
      "Epoch 00013: val_loss did not improve from 0.02593\n",
      "44625/44625 [==============================] - 2s 45us/sample - loss: 0.0169 - acc: 0.9941 - val_loss: 0.0399 - val_acc: 0.9859\n",
      "Epoch 14/40\n",
      "43520/44625 [============================>.] - ETA: 0s - loss: 0.0169 - acc: 0.9937\n",
      "Epoch 00014: val_loss did not improve from 0.02593\n",
      "44625/44625 [==============================] - 2s 44us/sample - loss: 0.0170 - acc: 0.9937 - val_loss: 1.2928 - val_acc: 0.7581\n",
      "Epoch 15/40\n",
      "43520/44625 [============================>.] - ETA: 0s - loss: 0.0185 - acc: 0.9935\n",
      "Epoch 00015: val_loss did not improve from 0.02593\n",
      "44625/44625 [==============================] - 2s 44us/sample - loss: 0.0185 - acc: 0.9935 - val_loss: 0.0611 - val_acc: 0.9764\n",
      "Epoch 16/40\n",
      "43520/44625 [============================>.] - ETA: 0s - loss: 0.0147 - acc: 0.9946\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.02593\n",
      "44625/44625 [==============================] - 2s 46us/sample - loss: 0.0146 - acc: 0.9947 - val_loss: 0.2580 - val_acc: 0.9295\n",
      "Epoch 17/40\n",
      "43520/44625 [============================>.] - ETA: 0s - loss: 0.0098 - acc: 0.9968\n",
      "Epoch 00017: val_loss improved from 0.02593 to 0.01394, saving model to cactusCNN.h5\n",
      "44625/44625 [==============================] - 2s 46us/sample - loss: 0.0097 - acc: 0.9968 - val_loss: 0.0139 - val_acc: 0.9954\n",
      "Epoch 18/40\n",
      "43520/44625 [============================>.] - ETA: 0s - loss: 0.0085 - acc: 0.9972\n",
      "Epoch 00018: val_loss did not improve from 0.01394\n",
      "44625/44625 [==============================] - 2s 45us/sample - loss: 0.0085 - acc: 0.9972 - val_loss: 0.0308 - val_acc: 0.9882\n",
      "Epoch 19/40\n",
      "43520/44625 [============================>.] - ETA: 0s - loss: 0.0068 - acc: 0.9976\n",
      "Epoch 00019: val_loss did not improve from 0.01394\n",
      "44625/44625 [==============================] - 2s 45us/sample - loss: 0.0069 - acc: 0.9975 - val_loss: 0.0418 - val_acc: 0.9859\n",
      "Epoch 20/40\n",
      "43520/44625 [============================>.] - ETA: 0s - loss: 0.0067 - acc: 0.9977\n",
      "Epoch 00020: val_loss did not improve from 0.01394\n",
      "44625/44625 [==============================] - 2s 45us/sample - loss: 0.0069 - acc: 0.9977 - val_loss: 0.0166 - val_acc: 0.9939\n",
      "Epoch 21/40\n",
      "43520/44625 [============================>.] - ETA: 0s - loss: 0.0070 - acc: 0.9977\n",
      "Epoch 00021: val_loss did not improve from 0.01394\n",
      "44625/44625 [==============================] - 2s 46us/sample - loss: 0.0070 - acc: 0.9977 - val_loss: 0.0240 - val_acc: 0.9905\n",
      "Epoch 22/40\n",
      "43520/44625 [============================>.] - ETA: 0s - loss: 0.0066 - acc: 0.9979\n",
      "Epoch 00022: val_loss did not improve from 0.01394\n",
      "44625/44625 [==============================] - 2s 46us/sample - loss: 0.0066 - acc: 0.9979 - val_loss: 0.0144 - val_acc: 0.9950\n",
      "Epoch 23/40\n",
      "43520/44625 [============================>.] - ETA: 0s - loss: 0.0068 - acc: 0.9975\n",
      "Epoch 00023: val_loss improved from 0.01394 to 0.01208, saving model to cactusCNN.h5\n",
      "44625/44625 [==============================] - 2s 47us/sample - loss: 0.0069 - acc: 0.9975 - val_loss: 0.0121 - val_acc: 0.9962\n",
      "Epoch 24/40\n",
      "43520/44625 [============================>.] - ETA: 0s - loss: 0.0063 - acc: 0.9978\n",
      "Epoch 00024: val_loss did not improve from 0.01208\n",
      "44625/44625 [==============================] - 2s 46us/sample - loss: 0.0063 - acc: 0.9978 - val_loss: 0.0149 - val_acc: 0.9954\n",
      "Epoch 25/40\n",
      "43520/44625 [============================>.] - ETA: 0s - loss: 0.0061 - acc: 0.9980\n",
      "Epoch 00025: val_loss did not improve from 0.01208\n",
      "44625/44625 [==============================] - 2s 45us/sample - loss: 0.0061 - acc: 0.9980 - val_loss: 0.0128 - val_acc: 0.9947\n",
      "Epoch 26/40\n",
      "43520/44625 [============================>.] - ETA: 0s - loss: 0.0065 - acc: 0.9977\n",
      "Epoch 00026: val_loss did not improve from 0.01208\n",
      "44625/44625 [==============================] - 2s 45us/sample - loss: 0.0064 - acc: 0.9977 - val_loss: 0.0494 - val_acc: 0.9851\n",
      "Epoch 27/40\n",
      "44544/44625 [============================>.] - ETA: 0s - loss: 0.0058 - acc: 0.9980\n",
      "Epoch 00027: val_loss did not improve from 0.01208\n",
      "44625/44625 [==============================] - 2s 45us/sample - loss: 0.0059 - acc: 0.9980 - val_loss: 0.0272 - val_acc: 0.9897\n",
      "Epoch 28/40\n",
      "43520/44625 [============================>.] - ETA: 0s - loss: 0.0060 - acc: 0.9980\n",
      "Epoch 00028: val_loss did not improve from 0.01208\n",
      "44625/44625 [==============================] - 2s 44us/sample - loss: 0.0061 - acc: 0.9980 - val_loss: 0.0125 - val_acc: 0.9950\n",
      "Epoch 29/40\n",
      "43520/44625 [============================>.] - ETA: 0s - loss: 0.0063 - acc: 0.9980\n",
      "Epoch 00029: val_loss did not improve from 0.01208\n",
      "44625/44625 [==============================] - 2s 45us/sample - loss: 0.0066 - acc: 0.9979 - val_loss: 0.0245 - val_acc: 0.9920\n",
      "Epoch 30/40\n",
      "43520/44625 [============================>.] - ETA: 0s - loss: 0.0062 - acc: 0.9980\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.01208\n",
      "44625/44625 [==============================] - 2s 45us/sample - loss: 0.0063 - acc: 0.9980 - val_loss: 0.0290 - val_acc: 0.9920\n",
      "Epoch 31/40\n",
      "43520/44625 [============================>.] - ETA: 0s - loss: 0.0061 - acc: 0.9978\n",
      "Epoch 00031: val_loss did not improve from 0.01208\n",
      "44625/44625 [==============================] - 2s 44us/sample - loss: 0.0061 - acc: 0.9978 - val_loss: 0.0142 - val_acc: 0.9954\n",
      "Epoch 32/40\n",
      "43520/44625 [============================>.] - ETA: 0s - loss: 0.0053 - acc: 0.9981\n",
      "Epoch 00032: val_loss did not improve from 0.01208\n",
      "44625/44625 [==============================] - 2s 44us/sample - loss: 0.0052 - acc: 0.9981 - val_loss: 0.0146 - val_acc: 0.9954\n",
      "Epoch 33/40\n",
      "43520/44625 [============================>.] - ETA: 0s - loss: 0.0051 - acc: 0.9983\n",
      "Epoch 00033: val_loss improved from 0.01208 to 0.01181, saving model to cactusCNN.h5\n",
      "44625/44625 [==============================] - 2s 46us/sample - loss: 0.0051 - acc: 0.9983 - val_loss: 0.0118 - val_acc: 0.9954\n",
      "Epoch 34/40\n",
      "43520/44625 [============================>.] - ETA: 0s - loss: 0.0046 - acc: 0.9985\n",
      "Epoch 00034: val_loss did not improve from 0.01181\n",
      "44625/44625 [==============================] - 2s 45us/sample - loss: 0.0045 - acc: 0.9985 - val_loss: 0.0142 - val_acc: 0.9950\n",
      "Epoch 35/40\n",
      "43520/44625 [============================>.] - ETA: 0s - loss: 0.0051 - acc: 0.9982\n",
      "Epoch 00035: val_loss did not improve from 0.01181\n",
      "44625/44625 [==============================] - 2s 44us/sample - loss: 0.0050 - acc: 0.9982 - val_loss: 0.0122 - val_acc: 0.9954\n",
      "Epoch 36/40\n",
      "43520/44625 [============================>.] - ETA: 0s - loss: 0.0051 - acc: 0.9983\n",
      "Epoch 00036: val_loss improved from 0.01181 to 0.01152, saving model to cactusCNN.h5\n",
      "44625/44625 [==============================] - 2s 45us/sample - loss: 0.0051 - acc: 0.9983 - val_loss: 0.0115 - val_acc: 0.9950\n",
      "Epoch 37/40\n",
      "43520/44625 [============================>.] - ETA: 0s - loss: 0.0049 - acc: 0.9984\n",
      "Epoch 00037: val_loss did not improve from 0.01152\n",
      "44625/44625 [==============================] - 2s 45us/sample - loss: 0.0049 - acc: 0.9984 - val_loss: 0.0149 - val_acc: 0.9954\n",
      "Epoch 38/40\n",
      "43520/44625 [============================>.] - ETA: 0s - loss: 0.0050 - acc: 0.9981\n",
      "Epoch 00038: val_loss did not improve from 0.01152\n",
      "44625/44625 [==============================] - 2s 45us/sample - loss: 0.0050 - acc: 0.9981 - val_loss: 0.0128 - val_acc: 0.9954\n",
      "Epoch 39/40\n",
      "43520/44625 [============================>.] - ETA: 0s - loss: 0.0050 - acc: 0.9984\n",
      "Epoch 00039: val_loss did not improve from 0.01152\n",
      "44625/44625 [==============================] - 2s 45us/sample - loss: 0.0050 - acc: 0.9984 - val_loss: 0.0117 - val_acc: 0.9958\n",
      "Epoch 40/40\n",
      "44544/44625 [============================>.] - ETA: 0s - loss: 0.0049 - acc: 0.9983\n",
      "Epoch 00040: val_loss did not improve from 0.01152\n",
      "44625/44625 [==============================] - 2s 44us/sample - loss: 0.0050 - acc: 0.9983 - val_loss: 0.0129 - val_acc: 0.9954\n"
     ]
    }
   ],
   "source": [
    "# Training - Fitting the model to the training data\n",
    "\n",
    "callbacks=[\n",
    "    ReduceLROnPlateau(monitor='val_loss',patience=7,min_lr=1e-9,verbose=1,mode='min'),\n",
    "    ModelCheckpoint('cactusCNN.h5',monitor='val_loss',save_best_only=True,verbose=1)]\n",
    "\n",
    "history = model.fit(np.asarray(train_img_list),np.asarray(train_label_list), \n",
    "          batch_size = 512, epochs = 40, \n",
    "          validation_data=(np.asarray(val_img_list),np.asarray(val_label_list)),\n",
    "            callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "010cb4c587b128cd6a58c467f4499034abd42be7"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the training curve \n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.legend(['train','valid'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "53b5e4641255284a7b30a5aa4838ce698a6ef6e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.4086385e-01],\n",
       "       [3.1590462e-06],\n",
       "       [9.9999630e-01],\n",
       "       [9.9975097e-01],\n",
       "       [2.4029273e-01]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performing predictions on the test images using the trained model\n",
    "\n",
    "test_predictions = model.predict(np.asarray(test_img_list))\n",
    "test_predictions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.94086385, 3.1590462e-06, 0.9999963, 0.999751, 0.24029273]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a submission for the Kaggle competition\n",
    "\n",
    "test_predictions_list = [pred[0] for pred in test_predictions]\n",
    "\n",
    "submission_data = {'id': test_img_id, 'has_cactus': test_predictions_list}\n",
    "submission_df = pd.DataFrame(submission_data)\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
